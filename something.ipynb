{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d23fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c76a2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = \"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\"\n",
    "MISTRALAI_API_KEY =\"XN1gUFU0bOnw0nDGERkN37MAOHwc4WdQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882f434c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = KEY\n",
    "\n",
    "if not os.getenv(\"MISTRALAI_API_KEY\"):\n",
    "    os.environ[\"MISTRALAI_API_KEY\"] = MISTRALAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af5b0e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"qwen/qwen3-32b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    reasoning_format=\"parsed\",\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")\n",
    "# from langchain_groq import ChatGroq\n",
    "\n",
    "# llm = ChatGroq(\n",
    "#     model=\"llama-3.1-8b-instant\",\n",
    "#     temperature=0,\n",
    "#     max_tokens=128,\n",
    "#     timeout=30,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "815da5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Okay, the user wants to translate \"I love apples.\" into French. Let me start by breaking down the sentence. \"I love\" is the subject and verb. In French, \"I\" is \"Je\" and \"love\" is \"aime\". Then \"apples\" is the object. The French word for apples is \"pommes\". So putting it together, it should be \"Je aime les pommes.\" Wait, but in French, after the verb \"aimer\", when using the pronoun \"je\", the verb needs to agree in number and person. Since \"je\" is first person singular, the correct conjugation is \"aime\". So \"Je aime\" is correct. But wait, sometimes in French, when the verb comes right after \"je\", you need to add a little \"s\" to make it \"j'aime\". Oh right! That's the elision. When \"je\" is followed by a vowel sound, you use \"j'\" instead of \"je\". Since \"aime\" starts with a vowel, it becomes \"j'aime\". So the correct translation is \"J'aime les pommes.\" Let me double-check that. Yes, \"j'aime\" is the correct form here. And \"les pommes\" is the plural of \"pomme\", which is correct. So the final translation should be \"J'aime les pommes.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant that translates English to French. Translate the user sentence.\",\n",
    "    ),\n",
    "    (\"human\", \"I love apples.\"),\n",
    "]\n",
    "\n",
    "ai_msg = llm.invoke(messages)\n",
    "\n",
    "\n",
    "msg = ai_msg.additional_kwargs.get('reasoning_content')\n",
    "\n",
    "reasoning_msg = AIMessage(content=msg)\n",
    "reasoning_msg.pretty_print()\n",
    "# ai_msg = llm.invoke(messages)\n",
    "# msg = ai_msg.additional_kwargs.get('reasoning_content')\n",
    "# ai_msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d2f9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qU langchain-community "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d8d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip -q install faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6e5699",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip -q install langchain_mistralai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1695aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mistralai import MistralAIEmbeddings\n",
    "\n",
    "embeddings = MistralAIEmbeddings(\n",
    "    model=\"mistral-embed\",\n",
    "    api_key= MISTRALAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f23a6da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embedding_dim = len(embeddings.embed_query(\"hello world\"))\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5f80e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5a9a981d-dc78-4cc0-ba44-05dfd280b6d5',\n",
       " '966bceab-5341-423a-8d9d-38dc3d8cb597',\n",
       " 'c080fb09-7aa5-451c-bf25-26f5bc178e29',\n",
       " '5e8cc3e4-6fcb-4d22-93d9-416c12b7997e',\n",
       " 'd8b67bd5-c6df-4064-b5c5-4822e0a3d9a0',\n",
       " '29a24d08-34fa-45e9-96da-9a8da8ad8c5d',\n",
       " '28fe959c-b0f3-4eeb-aa02-fb0a3cca5a7b',\n",
       " '4fbbe594-f681-4953-afde-affba47c26b0',\n",
       " 'de90e7b9-485b-49e2-b8de-c325d661771b',\n",
       " 'cf9647e6-0de2-405e-bf1a-5ddc738af2ef']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17ccb57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Building an exciting new project with LangChain - come check it out! [{'source': 'tweet'}]\n",
      "* LangGraph is the best framework for building stateful, agentic applications! [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search(\n",
    "    \"LangChain provides abstractions to make working with LLMs easy\",\n",
    "    k=2,\n",
    "    filter={\"source\": \"tweet\"},\n",
    ")\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af0a964a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [SIM=0.416781] The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees. [{'source': 'news'}]\n"
     ]
    }
   ],
   "source": [
    "results = vector_store.similarity_search_with_score(\n",
    "    \"Will it be hot tomorrow?\", k=1, filter={\"source\": \"news\"}\n",
    ")\n",
    "for res, score in results:\n",
    "    print(f\"* [SIM={score:3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2263637",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
